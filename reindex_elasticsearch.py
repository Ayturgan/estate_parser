#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤—Å–µ—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ Elasticsearch
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python reindex_elasticsearch.py
"""

import sys
import os
import logging
from datetime import datetime
from sqlalchemy.orm import Session

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.database import SessionLocal
from app import db_models
from app.utils.transform import transform_unique_ad, to_elasticsearch_dict
from app.services.elasticsearch_service import ElasticsearchService
from config import ELASTICSEARCH_HOSTS, ELASTICSEARCH_INDEX

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('reindex_elasticsearch.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
    logger.info("üöÄ Starting Elasticsearch reindexing...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞
    es_service = ElasticsearchService(
        hosts=ELASTICSEARCH_HOSTS,
        index_name=ELASTICSEARCH_INDEX
    )
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è Elasticsearch
    logger.info("üîç Checking Elasticsearch health...")
    health = es_service.health_check()
    if health.get('status') == 'error':
        logger.error(f"‚ùå Elasticsearch is not available: {health.get('error')}")
        return False
    
    logger.info(f"‚úÖ Elasticsearch is healthy: {health}")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã
    logger.info("üìä Fetching data from database...")
    db = SessionLocal()
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å –∏—Ö –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏
        unique_ads = db.query(db_models.DBUniqueAd).all()
        
        logger.info(f"üìà Found {len(unique_ads)} unique ads to reindex")
        
        if not unique_ads:
            logger.warning("‚ö†Ô∏è No ads found in database")
            return True
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è Elasticsearch
        ads_data = []
        for unique_ad in unique_ads:
            try:
                ad_dict = to_elasticsearch_dict(transform_unique_ad(unique_ad))
                ads_data.append(ad_dict)
            except Exception as e:
                logger.error(f"Error transforming ad {unique_ad.id}: {e}")
                continue
        
        logger.info(f"üîÑ Transformed {len(ads_data)} ads for indexing")
        
        # –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
        logger.info("üîÑ Starting reindexing...")
        start_time = datetime.now()
        
        success = es_service.reindex_all(ads_data)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        if success:
            logger.info(f"‚úÖ Reindexing completed successfully in {duration:.2f} seconds!")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = es_service.get_stats()
            logger.info(f"üìä Index stats: {stats}")
            
        else:
            logger.error("‚ùå Some errors occurred during reindexing")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error during reindexing: {e}")
        return False
        
    finally:
        db.close()
    
    logger.info("üéâ Reindexing process completed!")
    return True

def test_search():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
    logger.info("üß™ Testing search functionality...")
    
    es_service = ElasticsearchService(
        hosts=ELASTICSEARCH_HOSTS,
        index_name=ELASTICSEARCH_INDEX
    )
    
    try:
        # –¢–µ—Å—Ç 1: –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        result = es_service.search_ads(size=5)
        logger.info(f"‚úÖ Search test 1 - Found {result.get('total', 0)} total ads")
        
        # –¢–µ—Å—Ç 2: –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
        result = es_service.search_ads(
            query="–∫–≤–∞—Ä—Ç–∏—Ä–∞",
            filters={'is_realtor': False},
            size=3
        )
        logger.info(f"‚úÖ Search test 2 - Found {len(result.get('hits', []))} ads with filters")
        
        # –¢–µ—Å—Ç 3: –ê–≥—Ä–µ–≥–∞—Ü–∏–∏
        aggregations = es_service.get_aggregations()
        logger.info(f"‚úÖ Aggregations test - Got {len(aggregations)} aggregation types")
        
        # –¢–µ—Å—Ç 4: –ê–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ
        suggestions = es_service.suggest_addresses("–ë–∏—à–∫–µ–∫", 3)
        logger.info(f"‚úÖ Suggestions test - Got {len(suggestions)} suggestions")
        
        logger.info("üéâ All search tests passed!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Search test failed: {e}")
        return False

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Elasticsearch reindexing script')
    parser.add_argument('--test-only', action='store_true', 
                       help='Only test search functionality without reindexing')
    parser.add_argument('--reindex-only', action='store_true',
                       help='Only reindex without testing')
    
    args = parser.parse_args()
    
    if args.test_only:
        success = test_search()
    elif args.reindex_only:
        success = main()
    else:
        # –ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å: –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è + —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        success = main()
        if success:
            success = test_search()
    
    sys.exit(0 if success else 1) 