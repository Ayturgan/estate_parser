#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã—è—Å–Ω–µ–Ω–∏—è –ø—Ä–∏—á–∏–Ω "–∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—è" –æ–±—ä—è–≤–ª–µ–Ω–∏–π
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))

from sqlalchemy import create_engine, func, and_, or_, case
from sqlalchemy.orm import sessionmaker
from datetime import datetime, timedelta
import json

# –ü—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
DATABASE_URL = "postgresql://estate_user:admin123@localhost:5432/estate_db"

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
from app.database import db_models

def analyze_database_state():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    engine = create_engine(DATABASE_URL)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
    db = SessionLocal()
    
    try:
        print("üîç –ê–ù–ê–õ–ò–ó –°–û–°–¢–û–Ø–ù–ò–Ø –ë–ê–ó–´ –î–ê–ù–ù–´–•")
        print("=" * 50)
        
        # 1. –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        total_ads = db.query(func.count(db_models.DBAd.id)).scalar()
        total_unique_ads = db.query(func.count(db_models.DBUniqueAd.id)).scalar()
        total_duplicates = db.query(func.count(db_models.DBAd.id)).filter(db_models.DBAd.is_duplicate == True).scalar()
        total_base_ads = db.query(func.count(db_models.DBAd.id)).filter(db_models.DBAd.is_duplicate == False).scalar()
        
        print(f"–í—Å–µ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ DBAd: {total_ads}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ DBUniqueAd: {total_unique_ads}")
        print(f"–î—É–±–ª–∏–∫–∞—Ç–æ–≤: {total_duplicates}")
        print(f"–ë–∞–∑–æ–≤—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {total_base_ads}")
        
        # 2. –ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        print("\nüîç –ê–ù–ê–õ–ò–ó –ù–ï–û–ë–†–ê–ë–û–¢–ê–ù–ù–´–• –û–ë–™–Ø–í–õ–ï–ù–ò–ô:")
        unprocessed_ads = db.query(func.count(db_models.DBAd.id)).filter(
            db_models.DBAd.is_processed == False
        ).scalar()
        print(f"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {unprocessed_ads}")
        
        # 3. –ê–Ω–∞–ª–∏–∑ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        print("\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ò–°–¢–û–ß–ù–ò–ö–ê–ú:")
        sources_stats = db.query(
            db_models.DBAd.source_name,
            func.count(db_models.DBAd.id).label('total'),
            func.sum(case((db_models.DBAd.is_duplicate == True, 1), else_=0)).label('duplicates'),
            func.sum(case((db_models.DBAd.is_processed == False, 1), else_=0)).label('unprocessed')
        ).group_by(db_models.DBAd.source_name).all()
        
        for source_name, total, duplicates, unprocessed in sources_stats:
            print(f"  {source_name}: –≤—Å–µ–≥–æ={total}, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤={duplicates}, –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö={unprocessed}")
        
        # 4. –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–∞—Ç–∞–º
        print("\nüìÖ –ê–ù–ê–õ–ò–ó –ü–û –î–ê–¢–ê–ú (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π):")
        week_ago = datetime.now() - timedelta(days=7)
        daily_stats = db.query(
            func.date(db_models.DBAd.parsed_at).label('date'),
            func.count(db_models.DBAd.id).label('total'),
            func.sum(case((db_models.DBAd.is_duplicate == True, 1), else_=0)).label('duplicates'),
            func.sum(case((db_models.DBAd.is_processed == False, 1), else_=0)).label('unprocessed')
        ).filter(
            db_models.DBAd.parsed_at >= week_ago
        ).group_by(func.date(db_models.DBAd.parsed_at)).order_by(func.date(db_models.DBAd.parsed_at)).all()
        
        for date, total, duplicates, unprocessed in daily_stats:
            print(f"  {date}: –≤—Å–µ–≥–æ={total}, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤={duplicates}, –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö={unprocessed}")
        
        # 5. –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞
        print("\n‚ùå –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö:")
        error_ads = db.query(func.count(db_models.DBAd.id)).filter(
            or_(
                db_models.DBAd.title.is_(None),
                db_models.DBAd.title == '',
                db_models.DBAd.price.is_(None),
                db_models.DBAd.price == 0
            )
        ).scalar()
        print(f"–û–±—ä—è–≤–ª–µ–Ω–∏–π —Å –æ—à–∏–±–∫–∞–º–∏ (–ø—É—Å—Ç—ã–µ title/price): {error_ads}")
        
        # 6. –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏
        print("\nüîó –ê–ù–ê–õ–ò–ó –°–í–Ø–ó–ï–ô:")
        ads_with_unique = db.query(func.count(db_models.DBAd.id)).filter(
            db_models.DBAd.unique_ad_id.isnot(None)
        ).scalar()
        ads_without_unique = db.query(func.count(db_models.DBAd.id)).filter(
            db_models.DBAd.unique_ad_id.is_(None)
        ).scalar()
        print(f"–û–±—ä—è–≤–ª–µ–Ω–∏–π —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏: {ads_with_unique}")
        print(f"–û–±—ä—è–≤–ª–µ–Ω–∏–π –ù–ï —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏: {ads_without_unique}")
        
        # 7. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ "–∏—Å—á–µ–∑–Ω—É–≤—à–∏—Ö" –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        print("\nüîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó '–ò–°–ß–ï–ó–ù–£–í–®–ò–•' –û–ë–™–Ø–í–õ–ï–ù–ò–ô:")
        
        # –û–±—ä—è–≤–ª–µ–Ω–∏—è –±–µ–∑ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–µ–π –∏ –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
        orphan_ads = db.query(func.count(db_models.DBAd.id)).filter(
            and_(
                db_models.DBAd.unique_ad_id.is_(None),
                db_models.DBAd.is_duplicate == False
            )
        ).scalar()
        print(f"–û—Å–∏—Ä–æ—Ç–µ–≤—à–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π (–Ω–µ –¥—É–±–ª–∏–∫–∞—Ç—ã, –±–µ–∑ —Å–≤—è–∑–∏): {orphan_ads}")
        
        # –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        unprocessed_count = db.query(func.count(db_models.DBAd.id)).filter(
            db_models.DBAd.is_processed == False
        ).scalar()
        print(f"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {unprocessed_count}")
        
        # 8. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        
        if unprocessed_count > 0:
            print(f"  ‚ö†Ô∏è  –ï—Å—Ç—å {unprocessed_count} –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
            print("     –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—Ä–∞–±–æ—Ç–∫—É –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–ª—è –∏—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        if orphan_ads > 0:
            print(f"  ‚ö†Ô∏è  –ï—Å—Ç—å {orphan_ads} –æ–±—ä—è–≤–ª–µ–Ω–∏–π –±–µ–∑ —Å–≤—è–∑–∏ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏")
            print("     –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∏—á–∏–Ω–æ–π '–∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—è' –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        if error_ads > 0:
            print(f"  ‚ö†Ô∏è  –ï—Å—Ç—å {error_ads} –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å –æ—à–∏–±–∫–∞–º–∏")
            print("     –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö")
        
        # 9. –†–∞—Å—á–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        print("\nüìä –†–ï–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        real_total = total_ads
        real_unique = total_unique_ads + orphan_ads  # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–∏—Ä–æ—Ç–µ–≤—à–∏–µ
        real_duplicates = total_duplicates
        
        print(f"–í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ: {real_total}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {real_unique}")
        print(f"–î—É–±–ª–∏–∫–∞—Ç–æ–≤: {real_duplicates}")
        print(f"–†–∞–∑–Ω–∏—Ü–∞: {real_total - real_unique}")
        
        if real_total - real_unique != real_duplicates:
            print(f"  ‚ö†Ô∏è  –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ! –†–∞–∑–Ω–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–∞–≤–Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
            print(f"  –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã: –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–ª–∏ –æ—à–∏–±–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        db.close()

if __name__ == "__main__":
    analyze_database_state() 