#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–≤—É—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ü–û –û–¢–î–ï–õ–¨–ù–û–°–¢–ò:
1. –ü–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ (pHash, dHash, aHash) - –û–¢–î–ï–õ–¨–ù–û
2. –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π - –û–¢–î–ï–õ–¨–ù–û

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
python image_deduplication_test_separate.py
"""

import os
import sys
import logging
import numpy as np
from typing import List, Tuple, Dict, Optional
from pathlib import Path
import cv2
from PIL import Image
import imagehash
from sentence_transformers import SentenceTransformer
import torch
from transformers import CLIPProcessor, CLIPModel
import requests
from io import BytesIO

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PerceptualHashTester:
    """–¢–µ—Å—Ç–µ—Ä —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ–≥–æ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        self.hash_types = ['pHash', 'dHash', 'aHash', 'wHash', 'cHash']
        self.thresholds = {
            'pHash': 0.8,    # –ü–æ—Ä–æ–≥ –¥–ª—è –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ–≥–æ —Ö–µ—à–∞
            'dHash': 0.8,    # –ü–æ—Ä–æ–≥ –¥–ª—è —Ä–∞–∑–Ω–æ—Å—Ç–Ω–æ–≥–æ —Ö–µ—à–∞
            'aHash': 0.8,    # –ü–æ—Ä–æ–≥ –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ —Ö–µ—à–∞
            'wHash': 0.8,    # –ü–æ—Ä–æ–≥ –¥–ª—è –≤–µ–π–≤–ª–µ—Ç —Ö–µ—à–∞
            'cHash': 0.8,    # –ü–æ—Ä–æ–≥ –¥–ª—è —Ü–≤–µ—Ç–æ–≤–æ–≥–æ —Ö–µ—à–∞
        }
    
    def calculate_perceptual_hashes(self, image_path: str) -> Dict[str, str]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã—Ö —Ö–µ—à–µ–π –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            with Image.open(image_path) as img:
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                hashes = {
                    'pHash': str(imagehash.phash(img)),
                    'dHash': str(imagehash.dhash(img)),
                    'aHash': str(imagehash.average_hash(img)),
                    'wHash': str(imagehash.whash(img)),
                    'cHash': str(imagehash.colorhash(img)),
                }
                
                logger.info(f"–í—ã—á–∏—Å–ª–µ–Ω—ã —Ö–µ—à–∏ –¥–ª—è {image_path}: {list(hashes.keys())}")
                return hashes
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ö–µ—à–µ–π –¥–ª—è {image_path}: {e}")
            return {}
    
    def calculate_hamming_distance(self, hash1: str, hash2: str) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –•—ç–º–º–∏–Ω–≥–∞ –º–µ–∂–¥—É –¥–≤—É–º—è —Ö–µ—à–∞–º–∏"""
        if len(hash1) != len(hash2):
            return max(len(hash1), len(hash2))
        
        distance = 0
        for i in range(len(hash1)):
            if hash1[i] != hash2[i]:
                distance += 1
        return distance
    
    def calculate_perceptual_similarity(self, hashes1: Dict[str, str], hashes2: Dict[str, str]) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã—Ö —Ö–µ—à–µ–π"""
        similarities = {}
        
        for hash_type in self.hash_types:
            if hash_type in hashes1 and hash_type in hashes2:
                distance = self.calculate_hamming_distance(hashes1[hash_type], hashes2[hash_type])
                
                max_distances = {
                    'pHash': 64,
                    'dHash': 64,
                    'aHash': 64,
                    'wHash': 64,
                    'cHash': 42,
                }
                
                max_distance = max_distances.get(hash_type, 64)
                similarity = 1.0 - (distance / max_distance)
                similarities[hash_type] = max(0.0, similarity)
            else:
                similarities[hash_type] = 0.0
        
        return similarities
    
    def is_duplicate_by_perceptual_hash(self, image1_path: str, image2_path: str) -> Dict:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç –¢–û–õ–¨–ö–û –ø–æ –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã–º —Ö–µ—à–∞–º"""
        logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã–º–∏ —Ö–µ—à–∞–º–∏: {image1_path} vs {image2_path}")
        
        hashes1 = self.calculate_perceptual_hashes(image1_path)
        hashes2 = self.calculate_perceptual_hashes(image2_path)
        
        if not hashes1 or not hashes2:
            return {'is_duplicate': False, 'similarity': 0.0, 'method': 'perceptual_hash'}
        
        similarities = self.calculate_perceptual_similarity(hashes1, hashes2)
        avg_similarity = np.mean(list(similarities.values()))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ç–∏–ø —Ö–µ—à–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
        hash_results = {}
        for hash_type in self.hash_types:
            similarity = similarities.get(hash_type, 0.0)
            threshold = self.thresholds.get(hash_type, 0.8)
            hash_results[hash_type] = {
                'similarity': similarity,
                'is_duplicate': similarity > threshold,
                'threshold': threshold
            }
        
        # –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É –∑–Ω–∞—á–µ–Ω–∏—é
        overall_is_duplicate = avg_similarity > 0.8
        
        return {
            'is_duplicate': overall_is_duplicate,
            'similarity': avg_similarity,
            'method': 'perceptual_hash',
            'hash_results': hash_results,
            'hashes1': hashes1,
            'hashes2': hashes2
        }


class CLIPEmbeddingTester:
    """–¢–µ—Å—Ç–µ—Ä —Ç–æ–ª—å–∫–æ –¥–ª—è CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    
    def __init__(self):
        self.clip_model = None
        self.clip_processor = None
        self.threshold = 0.8  # –ü–æ—Ä–æ–≥ –¥–ª—è CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        self._load_models()
    
    def _load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ CLIP –º–æ–¥–µ–ª–∏"""
        try:
            logger.info("–ó–∞–≥—Ä—É–∂–∞–µ–º CLIP –º–æ–¥–µ–ª—å...")
            self.clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
            self.clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
            logger.info("CLIP –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CLIP –º–æ–¥–µ–ª–∏: {e}")
            self.clip_model = None
            self.clip_processor = None
    
    def get_image_embeddings(self, image_path: str) -> Optional[np.ndarray]:
        """–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é CLIP –º–æ–¥–µ–ª–∏"""
        if self.clip_model is None or self.clip_processor is None:
            logger.warning("CLIP –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return None
            
        try:
            image = Image.open(image_path).convert('RGB')
            inputs = self.clip_processor(images=image, return_tensors="pt")
            
            with torch.no_grad():
                image_features = self.clip_model.get_image_features(**inputs)
                
            embeddings = image_features.cpu().numpy()
            embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
            
            logger.info(f"–ü–æ–ª—É—á–µ–Ω—ã CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è {image_path}: {embeddings.shape}")
            return embeddings[0]
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {image_path}: {e}")
            return None
    
    def calculate_embedding_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏"""
        if embedding1 is None or embedding2 is None:
            return 0.0
            
        try:
            embedding1_norm = embedding1 / np.linalg.norm(embedding1)
            embedding2_norm = embedding2 / np.linalg.norm(embedding2)
            similarity = np.dot(embedding1_norm, embedding2_norm)
            return float(similarity)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ö–æ–¥—Å—Ç–≤–∞ CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            return 0.0
    
    def is_duplicate_by_clip_embedding(self, image1_path: str, image2_path: str) -> Dict:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç –¢–û–õ–¨–ö–û –ø–æ CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º"""
        logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏: {image1_path} vs {image2_path}")
        
        embedding1 = self.get_image_embeddings(image1_path)
        embedding2 = self.get_image_embeddings(image2_path)
        
        if embedding1 is None or embedding2 is None:
            return {'is_duplicate': False, 'similarity': 0.0, 'method': 'clip_embedding'}
        
        similarity = self.calculate_embedding_similarity(embedding1, embedding2)
        is_duplicate = similarity > self.threshold
        
        return {
            'is_duplicate': is_duplicate,
            'similarity': similarity,
            'method': 'clip_embedding',
            'threshold': self.threshold
        }


class SeparateImageDeduplicationTester:
    """–¢–µ—Å—Ç–µ—Ä –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞"""
    
    def __init__(self):
        self.perceptual_tester = PerceptualHashTester()
        self.clip_tester = CLIPEmbeddingTester()
    
    def test_perceptual_hash_only(self, image1_path: str, image2_path: str) -> Dict:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –¢–û–õ–¨–ö–û –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        print(f"\n{'='*60}")
        print(f"üîç –¢–ï–°–¢: –¢–û–õ–¨–ö–û –ü–ï–†–¶–ï–ü–¢–ò–í–ù–û–ï –•–ï–®–ò–†–û–í–ê–ù–ò–ï")
        print(f"{'='*60}")
        
        result = self.perceptual_tester.is_duplicate_by_perceptual_hash(image1_path, image2_path)
        self._print_perceptual_result(result, image1_path, image2_path)
        return result
    
    def test_clip_embedding_only(self, image1_path: str, image2_path: str) -> Dict:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –¢–û–õ–¨–ö–û CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∏"""
        print(f"\n{'='*60}")
        print(f"üîç –¢–ï–°–¢: –¢–û–õ–¨–ö–û CLIP –≠–ú–ë–ï–î–î–ò–ù–ì–ò")
        print(f"{'='*60}")
        
        result = self.clip_tester.is_duplicate_by_clip_embedding(image1_path, image2_path)
        self._print_clip_result(result, image1_path, image2_path)
        return result
    
    def test_both_methods_separately(self, image1_path: str, image2_path: str):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–±–∞ –º–µ—Ç–æ–¥–∞ –û–¢–î–ï–õ–¨–ù–û"""
        print(f"\n{'='*80}")
        print(f"üß™ –°–†–ê–í–ù–ï–ù–ò–ï –î–í–£–• –ü–û–î–•–û–î–û–í –û–¢–î–ï–õ–¨–ù–û")
        print(f"{'='*80}")
        print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 1: {Path(image1_path).name}")
        print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 2: {Path(image2_path).name}")
        print(f"{'='*80}")
        
        # –¢–µ—Å—Ç –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ–≥–æ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
        perceptual_result = self.test_perceptual_hash_only(image1_path, image2_path)
        
        # –¢–µ—Å—Ç CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        clip_result = self.test_clip_embedding_only(image1_path, image2_path)
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._print_comparison(perceptual_result, clip_result)
    
    def _print_perceptual_result(self, result: Dict, image1_path: str, image2_path: str):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ–≥–æ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 1: {Path(image1_path).name}")
        print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 2: {Path(image2_path).name}")
        print(f"{'-'*40}")
        
        if 'hash_results' in result:
            print(f"–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û –¢–ò–ü–ê–ú –•–ï–®–ï–ô:")
            for hash_type, hash_result in result['hash_results'].items():
                status = "‚úÖ –î–£–ë–õ–ò–ö–ê–¢" if hash_result['is_duplicate'] else "‚ùå –ù–ï –î–£–ë–õ–ò–ö–ê–¢"
                print(f"{hash_type:8}: {hash_result['similarity']:.3f} (–ø–æ—Ä–æ–≥: {hash_result['threshold']:.1f}) - {status}")
        
        print(f"\n–û–ë–©–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢:")
        print(f"–°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å: {result['similarity']:.3f}")
        status = "‚úÖ –î–£–ë–õ–ò–ö–ê–¢" if result['is_duplicate'] else "‚ùå –ù–ï –î–£–ë–õ–ò–ö–ê–¢"
        print(f"–†–µ—à–µ–Ω–∏–µ: {status}")
    
    def _print_clip_result(self, result: Dict, image1_path: str, image2_path: str):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 1: {Path(image1_path).name}")
        print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ 2: {Path(image2_path).name}")
        print(f"{'-'*40}")
        
        print(f"CLIP –≠–ú–ë–ï–î–î–ò–ù–ì–ò:")
        print(f"–°—Ö–æ–∂–µ—Å—Ç—å: {result['similarity']:.3f}")
        print(f"–ü–æ—Ä–æ–≥: {result['threshold']:.1f}")
        status = "‚úÖ –î–£–ë–õ–ò–ö–ê–¢" if result['is_duplicate'] else "‚ùå –ù–ï –î–£–ë–õ–ò–ö–ê–¢"
        print(f"–†–µ—à–µ–Ω–∏–µ: {status}")
    
    def _print_comparison(self, perceptual_result: Dict, clip_result: Dict):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–≤—É—Ö –º–µ—Ç–æ–¥–æ–≤"""
        print(f"\n{'='*60}")
        print(f"–°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print(f"{'='*60}")
        
        print(f"–ü–ï–†–¶–ï–ü–¢–ò–í–ù–´–ï –•–ï–®–ò:")
        print(f"  –°—Ö–æ–∂–µ—Å—Ç—å: {perceptual_result['similarity']:.3f}")
        print(f"  –†–µ—à–µ–Ω–∏–µ: {'‚úÖ –î–£–ë–õ–ò–ö–ê–¢' if perceptual_result['is_duplicate'] else '‚ùå –ù–ï –î–£–ë–õ–ò–ö–ê–¢'}")
        
        print(f"\nCLIP –≠–ú–ë–ï–î–î–ò–ù–ì–ò:")
        print(f"  –°—Ö–æ–∂–µ—Å—Ç—å: {clip_result['similarity']:.3f}")
        print(f"  –†–µ—à–µ–Ω–∏–µ: {'‚úÖ –î–£–ë–õ–ò–ö–ê–¢' if clip_result['is_duplicate'] else '‚ùå –ù–ï –î–£–ë–õ–ò–ö–ê–¢'}")
        
        # –ê–Ω–∞–ª–∏–∑ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
        agreement = perceptual_result['is_duplicate'] == clip_result['is_duplicate']
        print(f"\n–°–û–ì–õ–ê–°–û–í–ê–ù–ù–û–°–¢–¨ –ú–ï–¢–û–î–û–í:")
        if agreement:
            print(f"  ‚úÖ –ú–µ—Ç–æ–¥—ã —Å–æ–≥–ª–∞—Å–Ω—ã: {'–æ–±–∞ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏ –∫–∞–∫ –¥—É–±–ª–∏–∫–∞—Ç' if perceptual_result['is_duplicate'] else '–æ–±–∞ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏ –∫–∞–∫ –ù–ï –¥—É–±–ª–∏–∫–∞—Ç'}")
        else:
            print(f"  ‚ö†Ô∏è –ú–µ—Ç–æ–¥—ã –ù–ï —Å–æ–≥–ª–∞—Å–Ω—ã:")
            print(f"    - –ü–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã–µ —Ö–µ—à–∏: {'–¥—É–±–ª–∏–∫–∞—Ç' if perceptual_result['is_duplicate'] else '–ù–ï –¥—É–±–ª–∏–∫–∞—Ç'}")
            print(f"    - CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {'–¥—É–±–ª–∏–∫–∞—Ç' if clip_result['is_duplicate'] else '–ù–ï –¥—É–±–ª–∏–∫–∞—Ç'}")
    
    def test_with_sample_images(self, test_dir: str = "test_images"):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–±–∞ –º–µ—Ç–æ–¥–∞ –æ—Ç–¥–µ–ª—å–Ω–æ –Ω–∞ –≤—Å–µ—Ö –ø–∞—Ä–∞—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        test_path = Path(test_dir)
        if not test_path.exists():
            logger.error(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {test_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return
        
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
        image_files = [f for f in test_path.iterdir() if f.suffix.lower() in image_extensions]
        
        if len(image_files) < 2:
            logger.error(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ {test_dir}. –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2.")
            return
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        
        # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–∞—Ä—ã
        results = []
        for i in range(len(image_files)):
            for j in range(i + 1, len(image_files)):
                image1 = image_files[i]
                image2 = image_files[j]
                
                logger.info(f"\n{'='*50}")
                logger.info(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—É: {image1.name} vs {image2.name}")
                
                # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±–∞ –º–µ—Ç–æ–¥–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
                self.test_both_methods_separately(str(image1), str(image2))
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
                perceptual_result = self.perceptual_tester.is_duplicate_by_perceptual_hash(str(image1), str(image2))
                clip_result = self.clip_tester.is_duplicate_by_clip_embedding(str(image1), str(image2))
                
                results.append({
                    'image1': image1.name,
                    'image2': image2.name,
                    'perceptual': perceptual_result,
                    'clip': clip_result
                })
        
        # –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        self._print_summary_report(results)
    
    def _print_summary_report(self, results: List[Dict]):
        """–í—ã–≤–æ–¥–∏—Ç —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –≤—Å–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º"""
        print(f"\n{'='*80}")
        print(f"–°–í–û–î–ù–´–ô –û–¢–ß–ï–¢ –ü–û –û–¢–î–ï–õ–¨–ù–´–ú –ú–ï–¢–û–î–ê–ú")
        print(f"{'='*80}")
        
        total_pairs = len(results)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã–º —Ö–µ—à–∞–º
        perceptual_duplicates = sum(1 for r in results if r['perceptual']['is_duplicate'])
        perceptual_sims = [r['perceptual']['similarity'] for r in results]
        avg_perceptual_sim = np.mean(perceptual_sims) if perceptual_sims else 0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ CLIP —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º
        clip_duplicates = sum(1 for r in results if r['clip']['is_duplicate'])
        clip_sims = [r['clip']['similarity'] for r in results]
        avg_clip_sim = np.mean(clip_sims) if clip_sims else 0
        
        # –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤
        agreements = sum(1 for r in results if r['perceptual']['is_duplicate'] == r['clip']['is_duplicate'])
        
        print(f"–í—Å–µ–≥–æ –ø–∞—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_pairs}")
        print(f"\n–ü–ï–†–¶–ï–ü–¢–ò–í–ù–´–ï –•–ï–®–ò:")
        print(f"  –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {perceptual_duplicates}")
        print(f"  –ü—Ä–æ—Ü–µ–Ω—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {(perceptual_duplicates/total_pairs)*100:.1f}%")
        print(f"  –°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å: {avg_perceptual_sim:.3f}")
        
        print(f"\nCLIP –≠–ú–ë–ï–î–î–ò–ù–ì–ò:")
        print(f"  –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {clip_duplicates}")
        print(f"  –ü—Ä–æ—Ü–µ–Ω—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {(clip_duplicates/total_pairs)*100:.1f}%")
        print(f"  –°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å: {avg_clip_sim:.3f}")
        
        print(f"\n–°–û–ì–õ–ê–°–û–í–ê–ù–ù–û–°–¢–¨ –ú–ï–¢–û–î–û–í:")
        print(f"  –°–æ–≥–ª–∞—Å–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π: {agreements}/{total_pairs}")
        print(f"  –ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏: {(agreements/total_pairs)*100:.1f}%")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤"""
    print("üß™ –¢–ï–°–¢ –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–ò –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô (–û–¢–î–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´)")
    print("="*60)
    print("–≠—Ç–æ—Ç —Ç–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–≤–∞ –ø–æ–¥—Ö–æ–¥–∞ –∫ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –û–¢–î–ï–õ–¨–ù–û:")
    print("1. –ü–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ (pHash, dHash, aHash, wHash, cHash)")
    print("2. –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é CLIP –º–æ–¥–µ–ª–∏")
    print("="*60)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–µ—Ä
    tester = SeparateImageDeduplicationTester()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    test_dir = "test_images"
    if not os.path.exists(test_dir):
        print(f"\n‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {test_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        print(f"–°–æ–∑–¥–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é {test_dir} –∏ –ø–æ–º–µ—Å—Ç–∏—Ç–µ —Ç—É–¥–∞ —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        print(f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: 2 –ø–æ—Ö–æ–∂–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + 1 —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –¥—Ä—É–≥–æ–µ")
        return
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç
    print(f"\nüîç –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏–∑ {test_dir}...")
    tester.test_with_sample_images(test_dir)
    
    print(f"\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")


if __name__ == "__main__":
    main() 