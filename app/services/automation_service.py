import asyncio
import logging
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
from sqlalchemy.orm import Session
import aiohttp
from enum import Enum
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

logger = logging.getLogger(__name__)

class PipelineStatus(Enum):
    IDLE = "idle"
    RUNNING = "running" 
    COMPLETED = "completed"
    ERROR = "error"
    PAUSED = "paused"

class PipelineStage(Enum):
    SCRAPING = "scraping"
    PHOTO_PROCESSING = "photo_processing"
    DUPLICATE_PROCESSING = "duplicate_processing"
    REALTOR_DETECTION = "realtor_detection"
    ELASTICSEARCH_REINDEX = "elasticsearch_reindex"

class AutomationService:
    """–°–µ—Ä–≤–∏—Å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"""
    
    def __init__(self, api_base_url: str = "http://localhost:8000"):
        self.api_base_url = api_base_url
        self.session: Optional[aiohttp.ClientSession] = None
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞
        self.pipeline_status = PipelineStatus.IDLE
        self.current_stage: Optional[PipelineStage] = None
        self.last_run_start: Optional[datetime] = None
        self.last_run_end: Optional[datetime] = None
        self.next_run_scheduled: Optional[datetime] = None
        self.is_auto_mode = os.getenv('RUN_IMMEDIATELY_ON_START', 'false').lower() == 'true'
        self.interval_hours = int(os.getenv('PIPELINE_INTERVAL_HOURS', '3'))
        
        # –î–µ—Ç–∞–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        self.stage_details = {
            PipelineStage.SCRAPING: {
                "name": "–ü–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–æ–≤",
                "status": "idle",
                "started_at": None,
                "completed_at": None,
                "error": None,
                "progress": {
                    "total": 0, 
                    "completed": 0, 
                    "failed": 0,
                    "new_ads": 0,
                    "processed_ads": 0,
                    "sources_active": 0,
                    "sources_completed": 0
                }
            },
            PipelineStage.PHOTO_PROCESSING: {
                "name": "–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π", 
                "status": "idle",
                "started_at": None,
                "completed_at": None,
                "error": None,
                "progress": {
                    "processed": 0, 
                    "total": 0, 
                    "photos_downloaded": 0,
                    "photos_optimized": 0
                }
            },
            PipelineStage.DUPLICATE_PROCESSING: {
                "name": "–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤",
                "status": "idle", 
                "started_at": None,
                "completed_at": None,
                "error": None,
                "progress": {
                    "processed": 0, 
                    "remaining": 0, 
                    "duplicates_found": 0,
                    "groups_created": 0
                }
            },
            PipelineStage.REALTOR_DETECTION: {
                "name": "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤",
                "status": "idle",
                "started_at": None, 
                "completed_at": None,
                "error": None,
                "progress": {
                    "detected": 0, 
                    "processed": 0,
                    "total": 0
                }
            },
            PipelineStage.ELASTICSEARCH_REINDEX: {
                "name": "–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞",
                "status": "idle",
                "started_at": None,
                "completed_at": None, 
                "error": None,
                "progress": {
                    "indexed": 0, 
                    "total": 0
                }
            }
        }
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        self.enabled_stages = {
            PipelineStage.SCRAPING: os.getenv('ENABLE_SCRAPING', 'true').lower() == 'true',
            PipelineStage.PHOTO_PROCESSING: os.getenv('ENABLE_PHOTO_PROCESSING', 'true').lower() == 'true', 
            PipelineStage.DUPLICATE_PROCESSING: os.getenv('ENABLE_DUPLICATE_PROCESSING', 'true').lower() == 'true',
            PipelineStage.REALTOR_DETECTION: os.getenv('ENABLE_REALTOR_DETECTION', 'true').lower() == 'true',
            PipelineStage.ELASTICSEARCH_REINDEX: os.getenv('ENABLE_ELASTICSEARCH_REINDEX', 'true').lower() == 'true'
        }
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        sources_str = os.getenv('SCRAPING_SOURCES', 'house,lalafo,stroka')
        self.scraping_sources = [s.strip() for s in sources_str.split(',') if s.strip()]
        
        # –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞
        self._background_task: Optional[asyncio.Task] = None
        
        # –ò—Å—Ö–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –Ω–æ–≤—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        self.initial_stats = None
        
    async def start_service(self):
        """–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏"""
        if not self.session:
            self.session = aiohttp.ClientSession()
        
        if not self._background_task:
            self._background_task = asyncio.create_task(self._background_scheduler())
            
        logger.info("üöÄ –°–µ—Ä–≤–∏—Å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—É—â–µ–Ω")
    
    async def stop_service(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏"""
        if self._background_task:
            self._background_task.cancel()
            try:
                await self._background_task
            except asyncio.CancelledError:
                pass
            self._background_task = None
            
        if self.session:
            await self.session.close()
            self.session = None
            
        logger.info("üõë –°–µ—Ä–≤–∏—Å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    async def _background_scheduler(self):
        """–§–æ–Ω–æ–≤—ã–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
        while True:
            try:
                if (self.is_auto_mode and 
                    self.pipeline_status == PipelineStatus.IDLE and
                    self.next_run_scheduled and
                    datetime.now() >= self.next_run_scheduled):
                    
                    logger.info("‚è∞ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é")
                    await self.start_pipeline()
                
                await asyncio.sleep(60)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–µ: {e}")
                await asyncio.sleep(60)
    
    async def start_pipeline(self, manual: bool = False) -> bool:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        if self.pipeline_status == PipelineStatus.RUNNING:
            return False
            
        self.pipeline_status = PipelineStatus.RUNNING
        self.last_run_start = datetime.now()
        self.last_run_end = None
        
        if not manual:
            # –ü–ª–∞–Ω–∏—Ä—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫
            self.next_run_scheduled = datetime.now() + timedelta(hours=self.interval_hours)
        
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ ({'—Ä—É—á–Ω–æ–π' if manual else '–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π'})")
        
        try:
            success = True
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ —ç—Ç–∞–ø—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
            for stage in PipelineStage:
                if not self.enabled_stages.get(stage, False):
                    continue
                    
                self.current_stage = stage
                stage_success = await self._execute_stage(stage)
                
                if not stage_success:
                    success = False
                    break
            
            self.pipeline_status = PipelineStatus.COMPLETED if success else PipelineStatus.ERROR
            self.current_stage = None
            self.last_run_end = datetime.now()
            
            logger.info(f"‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω {'—É—Å–ø–µ—à–Ω–æ' if success else '—Å –æ—à–∏–±–∫–∞–º–∏'}")
            return success
            
        except Exception as e:
            self.pipeline_status = PipelineStatus.ERROR
            self.current_stage = None
            self.last_run_end = datetime.now()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞: {e}")
            return False
    
    async def _execute_stage(self, stage: PipelineStage) -> bool:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        stage_info = self.stage_details[stage]
        stage_info["status"] = "running"
        stage_info["started_at"] = datetime.now()
        stage_info["error"] = None
        
        try:
            if stage == PipelineStage.SCRAPING:
                success = await self._execute_scraping()
            elif stage == PipelineStage.PHOTO_PROCESSING:
                success = await self._execute_photo_processing()
            elif stage == PipelineStage.DUPLICATE_PROCESSING:
                success = await self._execute_duplicate_processing()
            elif stage == PipelineStage.REALTOR_DETECTION:
                success = await self._execute_realtor_detection()
            elif stage == PipelineStage.ELASTICSEARCH_REINDEX:
                success = await self._execute_elasticsearch_reindex()
            else:
                success = False
                
            stage_info["status"] = "completed" if success else "error"
            stage_info["completed_at"] = datetime.now()
            return success
            
        except Exception as e:
            stage_info["status"] = "error"
            stage_info["error"] = str(e)
            stage_info["completed_at"] = datetime.now()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç—Ç–∞–ø–∞ {stage.value}: {e}")
            return False
    
    async def _execute_scraping(self) -> bool:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —ç—Ç–∞–ø–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        await self._update_stats()
        
        job_ids = []
        progress = self.stage_details[PipelineStage.SCRAPING]["progress"]
        progress["total"] = len(self.scraping_sources)
        progress["completed"] = 0
        progress["failed"] = 0
        progress["sources_active"] = 0
        progress["sources_completed"] = 0
        progress["new_ads"] = 0
        progress["processed_ads"] = 0
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –ø–æ –≤—Å–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        for source in self.scraping_sources:
            try:
                async with self.session.post(f"{self.api_base_url}/api/scraping/start/{source}") as response:
                    if response.status in [200, 201, 202]:
                        data = await response.json()
                        job_id = data.get('job_id')
                        if job_id:
                            job_ids.append((source, job_id))
                            progress["sources_active"] += 1
                            logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ {source} –∑–∞–ø—É—â–µ–Ω (job_id: {job_id})")
                    else:
                        progress["failed"] += 1
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {source}")
            except Exception as e:
                progress["failed"] += 1
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {source}: {e}")
        
        if not job_ids:
            return False
            
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
        return await self._wait_for_scraping_completion(job_ids)
    
    async def _wait_for_scraping_completion(self, job_ids: list) -> bool:
        """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        progress = self.stage_details[PipelineStage.SCRAPING]["progress"]
        completed_jobs = set()
        
        while len(completed_jobs) < len(job_ids):
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
            await self._update_stats()
            
            for source, job_id in job_ids:
                if job_id in completed_jobs:
                    continue
                    
                try:
                    async with self.session.get(f"{self.api_base_url}/api/scraping/status/{job_id}") as response:
                        if response.status == 200:
                            data = await response.json()
                            status = data.get('status', 'unknown')
                            
                            if status in ['–∑–∞–≤–µ—Ä—à–µ–Ω–æ', '–æ—à–∏–±–∫–∞', '–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ']:
                                completed_jobs.add(job_id)
                                progress["sources_active"] -= 1
                                progress["sources_completed"] += 1
                                
                                if status == '–∑–∞–≤–µ—Ä—à–µ–Ω–æ':
                                    progress["completed"] += 1
                                    logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ {source}: –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                                else:
                                    progress["failed"] += 1
                                    logger.info(f"‚ùå –ü–∞—Ä—Å–∏–Ω–≥ {source}: –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–æ–π ({status})")
                            elif status == '–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è':
                                logger.info(f"‚è≥ –ü–∞—Ä—Å–∏–Ω–≥ {source}: –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è...")
                                
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ {source}: {e}")
            
            if len(completed_jobs) < len(job_ids):
                await asyncio.sleep(30)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        await self._update_stats()
        return progress["failed"] == 0
    
    async def _wait_for_process_completion(self, process_type: str) -> bool:
        """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ñ–æ–Ω–æ–≤—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤"""
        max_wait_time = 3600  # –ú–∞–∫—Å–∏–º—É–º 1 —á–∞—Å –æ–∂–∏–¥–∞–Ω–∏—è
        check_interval = 30   # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
        elapsed_time = 0
        
        while elapsed_time < max_wait_time:
            try:
                endpoint_map = {
                    "photos": "/api/process/photos/status",
                    "duplicates": "/api/process/duplicates/status", 
                    "realtors": "/api/process/realtors/status",
                    "elasticsearch": "/api/elasticsearch/health"
                }
                
                endpoint = endpoint_map.get(process_type)
                if not endpoint:
                    logger.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø—Ä–æ—Ü–µ—Å—Å–∞: {process_type}")
                    return False
                
                async with self.session.get(f"{self.api_base_url}{endpoint}") as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞
                        if process_type == "photos":
                            status = data.get('status', 'unknown')
                            if status in ['completed', 'idle']:
                                logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                                return True
                            elif status == 'error':
                                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π")
                                return False
                                
                        elif process_type == "duplicates":
                            status = data.get('status', 'unknown')
                            if status in ['completed', 'idle']:
                                logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                                return True
                            elif status == 'error':
                                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
                                return False
                                
                        elif process_type == "realtors":
                            status = data.get('status', 'unknown')
                            if status in ['completed', 'idle']:
                                logger.info(f"‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
                                return True
                            elif status == 'error':
                                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤")
                                return False
                                
                        elif process_type == "elasticsearch":
                            # –î–ª—è elasticsearch –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
                            logger.info(f"‚úÖ –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                            return True
                            
                        # –ï—Å–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å –µ—â–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è, –∂–¥–µ–º
                        logger.info(f"‚è≥ {process_type} –µ—â–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è, –æ–∂–∏–¥–∞–Ω–∏–µ...")
                        
                    else:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å {process_type}")
                        
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ {process_type}: {e}")
            
            await asyncio.sleep(check_interval)
            elapsed_time += check_interval
        
        logger.warning(f"‚è∞ –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è {process_type}")
        return False
    
    async def _execute_photo_processing(self) -> bool:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π"""
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
            async with self.session.post(f"{self.api_base_url}/api/process/photos") as response:
                if response.status not in [200, 201, 202]:
                    return False
                    
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
            logger.info("üì∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –∑–∞–ø—É—â–µ–Ω–∞, –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è...")
            return await self._wait_for_process_completion("photos")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ: {e}")
            return False
    
    async def _execute_duplicate_processing(self) -> bool:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            async with self.session.post(f"{self.api_base_url}/api/process/duplicates") as response:
                if response.status not in [200, 201, 202]:
                    return False
                    
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            logger.info("üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∑–∞–ø—É—â–µ–Ω–∞, –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è...")
            return await self._wait_for_process_completion("duplicates")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")
            return False
    
    async def _execute_realtor_detection(self) -> bool:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤"""
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤
            async with self.session.post(f"{self.api_base_url}/api/process/realtors/detect") as response:
                if response.status not in [200, 201, 202]:
                    return False
                    
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤
            logger.info("üë§ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤ –∑–∞–ø—É—â–µ–Ω–æ, –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è...")
            return await self._wait_for_process_completion("realtors")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤: {e}")
            return False
    
    async def _execute_elasticsearch_reindex(self) -> bool:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é
            async with self.session.post(f"{self.api_base_url}/api/elasticsearch/reindex") as response:
                if response.status not in [200, 201, 202]:
                    return False
                    
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            logger.info("üîç –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞, –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è...")
            return await self._wait_for_process_completion("elasticsearch")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏"""
        return {
            "pipeline_status": self.pipeline_status.value,
            "current_stage": self.current_stage.value if self.current_stage else None,
            "is_auto_mode": self.is_auto_mode,
            "interval_hours": self.interval_hours,
            "scraping_sources": self.scraping_sources,
            "last_run_start": self.last_run_start.isoformat() if self.last_run_start else None,
            "last_run_end": self.last_run_end.isoformat() if self.last_run_end else None,
            "next_run_scheduled": self.next_run_scheduled.isoformat() if self.next_run_scheduled else None,
            "enabled_stages": {stage.value: enabled for stage, enabled in self.enabled_stages.items()},
            "stage_details": {
                stage.value: {
                    **details,
                    "started_at": details["started_at"].isoformat() if details["started_at"] else None,
                    "completed_at": details["completed_at"].isoformat() if details["completed_at"] else None
                }
                for stage, details in self.stage_details.items()
            }
        }
    
    # –ú–µ—Ç–æ–¥—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–µ–∂–∏–º–æ–º —É–¥–∞–ª–µ–Ω—ã - –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ .env —Ñ–∞–π–ª
    
    def pause_pipeline(self):
        """–ü—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        if self.pipeline_status == PipelineStatus.RUNNING:
            self.pipeline_status = PipelineStatus.PAUSED
            logger.info("‚è∏Ô∏è –ü–∞–π–ø–ª–∞–π–Ω –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    def resume_pipeline(self):
        """–í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        if self.pipeline_status == PipelineStatus.PAUSED:
            self.pipeline_status = PipelineStatus.RUNNING
            logger.info("‚ñ∂Ô∏è –ü–∞–π–ø–ª–∞–π–Ω –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω")
    
    def stop_pipeline(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        if self.pipeline_status in [PipelineStatus.RUNNING, PipelineStatus.PAUSED]:
            self.pipeline_status = PipelineStatus.IDLE
            self.current_stage = None
            self.last_run_end = datetime.now()
            logger.info("üõë –ü–∞–π–ø–ª–∞–π–Ω –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    async def _update_stats(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            async with self.session.get(f"{self.api_base_url}/api/stats") as response:
                if response.status == 200:
                    current_stats = await response.json()
                    
                    if self.initial_stats is None:
                        self.initial_stats = current_stats.copy()
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–∞—Ä—Å–∏–Ω–≥–∞
                    if self.current_stage == PipelineStage.SCRAPING:
                        progress = self.stage_details[PipelineStage.SCRAPING]["progress"]
                        progress["new_ads"] = current_stats.get("total_original_ads", 0) - self.initial_stats.get("total_original_ads", 0)
                        progress["processed_ads"] = current_stats.get("total_unique_ads", 0) - self.initial_stats.get("total_unique_ads", 0)
                        
                    return current_stats
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        return None

    async def update_stage_status(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        if not self.session:
            return
            
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            await self._update_duplicates_status()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π
            await self._update_photos_status()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤
            await self._update_realtors_status()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–∞—Ä—Å–∏–Ω–≥–∞
            await self._update_scraping_status()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ —ç—Ç–∞–ø–æ–≤: {e}")
    
    async def _update_duplicates_status(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        try:
            async with self.session.get(f"{self.api_base_url}/api/process/duplicates/status") as response:
                if response.status == 200:
                    data = await response.json()
                    stage = self.stage_details[PipelineStage.DUPLICATE_PROCESSING]
                    status = data.get('status', 'idle')
                    
                    if status == 'running':
                        stage["status"] = "running"
                        if not stage["started_at"]:
                            stage["started_at"] = datetime.now()
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
                        progress = data.get('progress', {})
                        if progress:
                            stage["progress"].update(progress)
                            
                    elif status == 'completed':
                        stage["status"] = "completed"
                        if not stage["completed_at"]:
                            stage["completed_at"] = datetime.now()
                        
                        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ idle —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                        last_completed = data.get('last_completed')
                        if last_completed:
                            try:
                                from dateutil import parser
                                completed_time = parser.parse(last_completed)
                                if (datetime.now(completed_time.tzinfo) - completed_time).total_seconds() > 10:
                                    stage["status"] = "idle"
                                    stage["started_at"] = None
                                    stage["completed_at"] = None
                            except:
                                pass
                                
                    elif status == 'idle':
                        stage["status"] = "idle"
                        stage["started_at"] = None
                        stage["completed_at"] = None
                        
                    elif status == 'error':
                        stage["status"] = "error"
                        stage["error"] = data.get('error', '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞')
                        stage["completed_at"] = datetime.now()
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")
    
    async def _update_photos_status(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π"""
        try:
            async with self.session.get(f"{self.api_base_url}/api/process/photos/status") as response:
                if response.status == 200:
                    data = await response.json()
                    stage = self.stage_details[PipelineStage.PHOTO_PROCESSING]
                    status = data.get('status', 'idle')
                    
                    if status == 'running':
                        stage["status"] = "running"
                        if not stage["started_at"]:
                            stage["started_at"] = datetime.now()
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
                        progress = data.get('progress', {})
                        if progress:
                            stage["progress"].update(progress)
                            
                    elif status == 'completed':
                        stage["status"] = "completed"
                        if not stage["completed_at"]:
                            stage["completed_at"] = datetime.now()
                        
                        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ idle —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                        last_completed = data.get('last_completed')
                        if last_completed:
                            try:
                                from dateutil import parser
                                completed_time = parser.parse(last_completed)
                                if (datetime.now(completed_time.tzinfo) - completed_time).total_seconds() > 10:
                                    stage["status"] = "idle"
                                    stage["started_at"] = None
                                    stage["completed_at"] = None
                            except:
                                pass
                                
                    elif status == 'idle':
                        stage["status"] = "idle"
                        stage["started_at"] = None
                        stage["completed_at"] = None
                        
                    elif status == 'error':
                        stage["status"] = "error"
                        stage["error"] = data.get('error', '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞')
                        stage["completed_at"] = datetime.now()
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π: {e}")
    
    async def _update_realtors_status(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤"""
        try:
            async with self.session.get(f"{self.api_base_url}/api/process/realtors/status") as response:
                if response.status == 200:
                    data = await response.json()
                    stage = self.stage_details[PipelineStage.REALTOR_DETECTION]
                    status = data.get('status', 'idle')
                    
                    if status == 'running':
                        stage["status"] = "running"
                        if not stage["started_at"]:
                            stage["started_at"] = datetime.now()
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
                        progress = data.get('progress', {})
                        if progress:
                            stage["progress"].update(progress)
                            
                    elif status == 'completed':
                        stage["status"] = "completed"
                        if not stage["completed_at"]:
                            stage["completed_at"] = datetime.now()
                        
                        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ idle —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                        last_completed = data.get('last_completed')
                        if last_completed:
                            try:
                                from dateutil import parser
                                completed_time = parser.parse(last_completed)
                                if (datetime.now(completed_time.tzinfo) - completed_time).total_seconds() > 10:
                                    stage["status"] = "idle"
                                    stage["started_at"] = None
                                    stage["completed_at"] = None
                            except:
                                pass
                                
                    elif status == 'idle':
                        stage["status"] = "idle"
                        stage["started_at"] = None
                        stage["completed_at"] = None
                        
                    elif status == 'error':
                        stage["status"] = "error"
                        stage["error"] = data.get('error', '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞')
                        stage["completed_at"] = datetime.now()
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Ä–∏—ç–ª—Ç–æ—Ä–æ–≤: {e}")
    
    async def _update_scraping_status(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        try:
            async with self.session.get(f"{self.api_base_url}/api/scraping/jobs") as response:
                if response.status == 200:
                    jobs = await response.json()
                    stage = self.stage_details[PipelineStage.SCRAPING]
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
                    running_jobs = [job for job in jobs if job.get('status') == '–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è']
                    
                    if running_jobs:
                        stage["status"] = "running"
                        if not stage["started_at"]:
                            stage["started_at"] = datetime.now()
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–∞—Ä—Å–∏–Ω–≥–∞
                        progress = stage["progress"]
                        progress["sources_active"] = len(running_jobs)
                        progress["total"] = len(self.scraping_sources)
                        
                        # –°—á–∏—Ç–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
                        completed_sources = 0
                        for source in self.scraping_sources:
                            source_jobs = [j for j in jobs if j.get('config') == source]
                            if source_jobs:
                                latest_job = max(source_jobs, key=lambda x: x.get('created_at', ''))
                                if latest_job.get('status') == '–∑–∞–≤–µ—Ä—à–µ–Ω–æ':
                                    completed_sources += 1
                        
                        progress["sources_completed"] = completed_sources
                        
                    else:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±—ã–ª–∏ –ª–∏ –Ω–µ–¥–∞–≤–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
                        recent_completed = [job for job in jobs if job.get('status') == '–∑–∞–≤–µ—Ä—à–µ–Ω–æ']
                        if recent_completed and stage["status"] == "running":
                            stage["status"] = "completed"
                            stage["completed_at"] = datetime.now()
                        elif stage["status"] not in ["completed"]:
                            stage["status"] = "idle"
                            
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
automation_service = AutomationService() 